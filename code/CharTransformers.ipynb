{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "125af93c-648b-4394-a8fc-80d6f82d0a8a",
      "metadata": {
        "id": "125af93c-648b-4394-a8fc-80d6f82d0a8a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e0fe960-0a13-41a5-950d-7f0bac62b182",
      "metadata": {
        "id": "5e0fe960-0a13-41a5-950d-7f0bac62b182"
      },
      "outputs": [],
      "source": [
        "file_path = \"../data/alpaca_data_cleaned_subset.json\"\n",
        "context_length = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "55607749-deef-492d-8913-6f03363170af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55607749-deef-492d-8913-6f03363170af",
        "outputId": "ce70f6f6-b69d-4a22-d19d-5d61ffd8f084"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training examples: 19261\n",
            "Example input shape: (330,)\n",
            "output shape: (19261, 33)\n"
          ]
        }
      ],
      "source": [
        "def read_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "def preprocess_data(data):\n",
        "    sequences = []\n",
        "    for item in data:\n",
        "        sequence = ['[SOS]'] + list(item['instruction']) + ['\\n'] + list(item['input']) + ['\\n'] + list(item['output']) + ['[EOS]']\n",
        "        sequences.append(sequence)\n",
        "    return sequences\n",
        "\n",
        "valid_chars = list('abcdefghijklmnopqrstuvwxyz ?!.,\\n')\n",
        "def preprocess_data_simple(data):\n",
        "    sequences = []\n",
        "    for item in data:\n",
        "        instruction_alpha = ''.join([char for char in item['instruction'].lower() if char in valid_chars])\n",
        "        input_alpha = ''.join([char for char in item['input'].lower() if char in valid_chars])\n",
        "        output_alpha = ''.join([char for char in item['output'].lower() if char in valid_chars])\n",
        "\n",
        "        sequence = ['[SOS]'] + list(instruction_alpha) + ['\\n'] + list(input_alpha) + ['\\n'] + list(output_alpha) + ['[EOS]']\n",
        "        sequences.append(sequence)\n",
        "    return sequences\n",
        "\n",
        "# Add another character for the beginning of the sequence (or maybe just continue with [SOS]?) When there are no characters at the beginning of the sequence.\n",
        "\n",
        "def create_vocab(sequences):\n",
        "    chars = [char for seq in sequences for char in seq]\n",
        "    return sorted(set(chars))\n",
        "\n",
        "def one_hot_encode(sequence, char_to_idx):\n",
        "    one_hot = np.zeros((len(sequence), len(char_to_idx)), dtype=np.int32)\n",
        "    for i, char in enumerate(sequence):\n",
        "        one_hot[i, char_to_idx[char]] = 1\n",
        "    return one_hot\n",
        "\n",
        "def numerical_encode(sequence, char_to_idx):\n",
        "    numerical_encoding = np.zeros(len(sequence), dtype=np.int32)\n",
        "    for i, char in enumerate(sequence):\n",
        "        numerical_encoding[i] = char_to_idx[char]\n",
        "    return numerical_encoding\n",
        "\n",
        "def create_training_examples(sequences, char_to_idx, input_length=10):\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for seq in sequences:\n",
        "        encoded_seq = one_hot_encode(seq, char_to_idx)\n",
        "        numerical_encode_seq = numerical_encode(seq, char_to_idx)\n",
        "        total_chars = len(seq)\n",
        "\n",
        "        for i in range(total_chars - input_length):\n",
        "            x.append(encoded_seq[i:i+input_length])\n",
        "            y.append(encoded_seq[i+input_length])\n",
        "\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "# Main script\n",
        "data = read_json(file_path)\n",
        "#sequences = preprocess_data(data)\n",
        "sequences = preprocess_data_simple(data)\n",
        "\n",
        "vocab = create_vocab(sequences)\n",
        "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
        "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
        "\n",
        "X, Y = create_training_examples(sequences, char_to_idx, input_length=context_length)\n",
        "X = X.reshape(X.shape[0], -1)\n",
        "\n",
        "print(f\"Number of training examples: {X.shape[0]}\")\n",
        "print(f\"Example input shape: {X[0].shape}\")\n",
        "print(f\"output shape: {Y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "AGWT8b5YeCNx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGWT8b5YeCNx",
        "outputId": "ceab3061-a515-4eda-d00a-7f89b26c33ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((19261, 330), (19261, 33))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "2edf3074-9298-485a-81b9-a94b33727443",
      "metadata": {
        "id": "2edf3074-9298-485a-81b9-a94b33727443"
      },
      "outputs": [],
      "source": [
        "X = X[0:5_000_000]\n",
        "Y = Y[0:5_000_000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ajz79n6jd5_r",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajz79n6jd5_r",
        "outputId": "4a6eaa89-798d-4b46-ba09-89f072a70cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "      dtype=int32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "pz1-EI8yd1J8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz1-EI8yd1J8",
        "outputId": "375152c9-fe28-43a3-852b-11930f659371"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "JuLR8rKxd0Wi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuLR8rKxd0Wi",
        "outputId": "aa7b7895-23b6-4944-d915-8721b5762d2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((19261, 330), (19261, 33))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ytteIh2vhrtQ",
      "metadata": {
        "id": "ytteIh2vhrtQ"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "hBLcvY5Mh9Q5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBLcvY5Mh9Q5",
        "outputId": "bbc02d06-e5aa-4314-e889-12619bd1b407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((15408, 330), (15408, 33))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "XLykUMHL9Cfa",
      "metadata": {
        "id": "XLykUMHL9Cfa"
      },
      "outputs": [],
      "source": [
        "input_size = 340  # Assuming 340 characters in the vocabulary\n",
        "output_size = 34  # Output is the index of the next character\n",
        "embed_size = 32\n",
        "num_heads = 1 # 2\n",
        "num_layers = 1 # 2\n",
        "batch_size = 8\n",
        "learning_rate = 0.01 # 0.01\n",
        "weight_decay = 1e-5  # Adjust the weight decay value as needed\n",
        "num_epochs = 2 # 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "MEASNC5SiOUQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEASNC5SiOUQ",
        "outputId": "3005544a-0e1f-45f4-e7c6-ad257ef83678"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "Epoch 1/10:   0%|          | 0/1926 [00:00<?, ?it/s]/var/folders/y8/xy6xy9s53flg2nvj1bdcfx6h0000gn/T/ipykernel_42657/54630098.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_tensor = torch.tensor(inputs).long()\n",
            "/var/folders/y8/xy6xy9s53flg2nvj1bdcfx6h0000gn/T/ipykernel_42657/54630098.py:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target_tensor = torch.tensor(targets).long()\n",
            "Epoch 1/10: 100%|██████████| 1926/1926 [06:11<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.009958996237089486, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 1926/1926 [05:58<00:00,  5.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Loss: 0.005765530230630024, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 1926/1926 [06:05<00:00,  5.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Loss: 0.005493828691024898, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 1926/1926 [05:55<00:00,  5.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Loss: 0.004959368609379717, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 1926/1926 [06:01<00:00,  5.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Loss: 0.00551295438841598, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 1926/1926 [06:02<00:00,  5.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Loss: 0.005464767994692194, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 1926/1926 [05:58<00:00,  5.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Loss: 0.004958967814159313, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 1926/1926 [05:58<00:00,  5.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Loss: 0.005621875166058545, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 1926/1926 [05:58<00:00,  5.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Loss: 0.005259834920566641, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 1926/1926 [05:58<00:00,  5.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Loss: 0.004956257450301324, Accuracy: 6.49%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the Transformer model for sequence-to-sequence prediction\n",
        "class CharTransformer(nn.Module):\n",
        "    def __init__(self, input_size, output_size, embed_size, num_heads, num_layers):\n",
        "        super(CharTransformer, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, embed_size)\n",
        "        self.transformer = nn.Transformer(\n",
        "            d_model=embed_size,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "        )\n",
        "        self.fc = nn.Linear(embed_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.transformer(x, x)\n",
        "\n",
        "        # Take the representation of the last token from each sequence\n",
        "        x_last_token = x[:, -1, :]\n",
        "\n",
        "        # Apply the linear layer to each sequence\n",
        "        output = self.fc(x_last_token)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Define a custom dataset\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        input_vector = self.X[idx]\n",
        "        target_index = self.Y[idx]\n",
        "        return input_vector, target_index\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 340  # Assuming 340 characters in the vocabulary\n",
        "output_size = 34  # Output is the index of the next character\n",
        "embed_size = 32\n",
        "num_heads = 2 # 2\n",
        "num_layers = 2 # 2\n",
        "batch_size = 8\n",
        "learning_rate = 0.01 # 0.01\n",
        "weight_decay = 1e-5  # Adjust the weight decay value as needed\n",
        "num_epochs = 10 # 10\n",
        "\n",
        "\n",
        "\n",
        "# Create model, loss, and optimizer\n",
        "model = CharTransformer(input_size, output_size, embed_size, num_heads, num_layers)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# Create the dataset and DataLoader\n",
        "dataset = CharDataset(X_train, Y_train)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    for batch in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
        "        inputs, targets = batch\n",
        "\n",
        "        # Convert inputs to PyTorch tensor\n",
        "        input_tensor = torch.tensor(inputs).long()\n",
        "        # print(inputs.shape, input_tensor.shape)\n",
        "        target_tensor = torch.tensor(targets).long()\n",
        "        # print(targets.shape, target_tensor.shape)\n",
        "\n",
        "        # Add batch and sequence dimensions\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_tensor)\n",
        "\n",
        "        # Ensure the output has shape (batch_size, output_size)\n",
        "        # print(\"output shape:\", outputs.shape)\n",
        "\n",
        "        # CrossEntropyLoss expects target_tensor to have shape (batch_size,)\n",
        "        target_tensor = target_tensor[:, -1]  # Take the last character as the target\n",
        "        target_tensor = target_tensor.view(-1)\n",
        "\n",
        "        # Check if batch sizes match before calculating the loss\n",
        "        assert outputs.size(0) == target_tensor.size(0), \"Batch sizes do not match\"\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, target_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate accuracy on this batch\n",
        "        # Get predicted characters (argmax along the second dimension)\n",
        "        predicted_chars = torch.argmax(outputs, dim=1)  # Use dim=1 for the second dimension\n",
        "        true_chars = torch.nonzero(targets, as_tuple=False)[:, 1]\n",
        "\n",
        "        # Count correct predictions\n",
        "        correct_predictions = (predicted_chars == true_chars)\n",
        "        total_correct += correct_predictions.sum().item()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    accuracy = total_correct / len(dataloader)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {average_loss}, Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Save the trained model\n",
        "torch.save(model.state_dict(), 'char_transformer_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2-HaLXngx221",
      "metadata": {
        "id": "2-HaLXngx221"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
            "/var/folders/y8/xy6xy9s53flg2nvj1bdcfx6h0000gn/T/ipykernel_42657/550107254.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  input_tensor = torch.tensor(inputs).long()\n",
            "/var/folders/y8/xy6xy9s53flg2nvj1bdcfx6h0000gn/T/ipykernel_42657/550107254.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  target_tensor = torch.tensor(targets).long()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.83%\n"
          ]
        }
      ],
      "source": [
        "# Load the trained model\n",
        "model = CharTransformer(input_size, output_size, embed_size, num_heads, num_layers)\n",
        "model.load_state_dict(torch.load('char_transformer_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Create the test dataset and DataLoader\n",
        "test_dataset = CharDataset(X_test, Y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Evaluation loop\n",
        "total_correct = 0\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        inputs, targets = batch\n",
        "\n",
        "        # Convert inputs to PyTorch tensor\n",
        "        input_tensor = torch.tensor(inputs).long()\n",
        "        target_tensor = torch.tensor(targets).long()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_tensor)\n",
        "\n",
        "        # Get predicted characters (argmax along the second dimension)\n",
        "        predicted_chars = torch.argmax(outputs, dim=1)  # Use dim=1 for the second dimension\n",
        "        true_chars = torch.nonzero(targets, as_tuple=False)[:, 1]\n",
        "\n",
        "        # Count correct predictions\n",
        "        correct_predictions = (predicted_chars == true_chars)\n",
        "        total_correct += correct_predictions.sum().item()\n",
        "        total_samples += correct_predictions.size(0)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = total_correct / total_samples\n",
        "print(f'Test Accuracy: {accuracy * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad8873e7-d9a1-4406-88be-74a503c89b1c",
      "metadata": {
        "id": "ad8873e7-d9a1-4406-88be-74a503c89b1c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
